{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opf_ensemble import OpfSemble\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from opfython.models.unsupervised import UnsupervisedOPF\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(classifiers_feats, X_valid, y_valid):\n",
    "    k_max = [5,10,20,30,40,50]\n",
    "    best_k = 0\n",
    "    value_best_k = -1.0\n",
    "\n",
    "    results_validation=[]\n",
    "    for k in k_max:\n",
    "        opf_ens.fit_meta_model(classifiers_feats,k)\n",
    "        accuracy, f1 = computeMetrics(opf_ens.predict(X_valid),y_valid)\n",
    "        results_validation.append([k, accuracy, f1])\n",
    "        if f1>value_best_k:\n",
    "            best_k = k\n",
    "            value_best_k = f1        \n",
    "    return best_k, results_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(classifiers_feats, X_test, X_valid, y_valid):\n",
    "    best_k, results_validation = validation(classifiers_feats, X_valid, y_valid)\n",
    "    opf_ens.fit_meta_model(classifiers_feats,best_k)\n",
    "    return opf_ens.predict(X_test), best_k, results_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResults(pred_ensamble,y_test, best_k, validation, exec_time, path):\n",
    "\n",
    "    results = ''\n",
    "    accuracy, f1 = computeMetrics(pred_ensamble,y_test)\n",
    "    results = results + '{:s},{:d},{:.4f},{:.4f},{:.4f}\\n'.format('OPF_ENSEMBLE',best_k, accuracy, f1, exec_time)\n",
    "    \n",
    "    for key in opf_ens.ensemble:\n",
    "        model = opf_ens.ensemble[key]\n",
    "        pred = model.predict(X_test)\n",
    "        accuracy, f1 = computeMetrics(pred,y_test)\n",
    "        results = results + '{:s},{:d},{:.4f},{:.4f},{:.4f}\\n'.format(key,0, accuracy, f1, 0)\n",
    "    \n",
    "\n",
    "    \n",
    "    np.savetxt('{}/pred.txt'.format(path), pred, fmt='%d')\n",
    "    np.savetxt('{}/validation.txt'.format(path), validation, fmt='%d,%.5f,%.5f')\n",
    "    output= open('{}/results.txt'.format(path), \"w\")    \n",
    "    output.write(results)\n",
    "    print('Results:')\n",
    "    print('    {}/pred.txt'.format(path))\n",
    "    print('    {}/results.txt'.format(path))\n",
    "    print('    {}/validation.txt'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "    Results/OPF_Ensamble/vertebral_column/1/10/pred.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/1/10/results.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/1/10/validation.txt\n",
      "Results:\n",
      "    Results/OPF_Ensamble/vertebral_column/2/10/pred.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/2/10/results.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/2/10/validation.txt\n",
      "Results:\n",
      "    Results/OPF_Ensamble/vertebral_column/1/30/pred.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/1/30/results.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/1/30/validation.txt\n",
      "Results:\n",
      "    Results/OPF_Ensamble/vertebral_column/2/30/pred.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/2/30/results.txt\n",
      "    Results/OPF_Ensamble/vertebral_column/2/30/validation.txt\n"
     ]
    }
   ],
   "source": [
    "datasets = ['vertebral_column']\n",
    "n_models = [10,30]#,50,100]\n",
    "\n",
    "for ds in datasets:\n",
    "    for n in n_models:\n",
    "        for f in range(1,3):\n",
    "            \n",
    "            ResultsPath = 'Results/OPF_Ensamble/{}/{}/{}'.format(ds,f,n)\n",
    "            if not os.path.exists(ResultsPath):\n",
    "                os.makedirs(ResultsPath)\n",
    "\n",
    "            train = np.loadtxt('data/{}/{}/train.txt'.format(ds,f),delimiter=',', dtype=np.float32)\n",
    "            valid = np.loadtxt('data/{}/{}/valid.txt'.format(ds,f),delimiter=',', dtype=np.float32)\n",
    "            test = np.loadtxt('data/{}/{}/test.txt'.format(ds,f),delimiter=',', dtype=np.float32)\n",
    "\n",
    "            X = train[:,:-1]\n",
    "            y = train[:,-1].astype(np.int) \n",
    "\n",
    "            X_valid = valid[:,:-1]\n",
    "            y_valid = valid[:,-1].astype(np.int) \n",
    "\n",
    "            X_test = test[:,:-1]\n",
    "            y_test = test[:,-1].astype(np.int) \n",
    "\n",
    "            start_time = time()\n",
    "            opf_ens = OpfSemble(n_models=n, n_folds=10)\n",
    "            new_x = opf_ens.fit(X, y)\n",
    "            pred_ensamble, best_k, validation_results = run(new_x, X_test, X_valid, y_valid)\n",
    "            end_time = time() -start_time\n",
    "\n",
    "            saveResults(pred_ensamble, y_test, best_k, validation_results, end_time, ResultsPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
